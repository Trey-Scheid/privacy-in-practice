@article{breiman2011,
  issn      = {08834237},
  url       = {http://www.jstor.org/stable/2676681},
  abstract  = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
  author    = {Leo Breiman},
  journal   = {Statistical Science},
  number    = {3},
  pages     = {199--215},
  publisher = {Institute of Mathematical Statistics},
  title     = {Statistical Modeling: The Two Cultures},
  urldate   = {2023-10-27},
  volume    = {16},
  year      = {2001}
}

@inproceedings{devlin2019bert,
  title     = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author    = {Devlin, Jacob  and
               Chang, Ming-Wei  and
               Lee, Kenton  and
               Toutanova, Kristina},
  booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month     = jun,
  year      = {2019},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/N19-1423},
  doi       = {10.18653/v1/N19-1423},
  pages     = {4171--4186},
  abstract  = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).}
}

@inproceedings{vaswani2023attention,
  title     = {Attention Is All You Need},
  author    = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages     = {},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
  volume    = {30},
  year      = {2017}
}

@inproceedings{karras2019stylebased,
  title     = {A Style-Based Generator Architecture for Generative Adversarial Networks},
  author    = {Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {4396-4405},
  doi       = {10.1109/CVPR.2019.00453}
}

@unpublished{Kwasnick2023,
  author    = {Robert Kwasnick},
  title     = {Exploration of CPU Error Dependencies and Prediction},
  note      = {Unpublished},
  year      = {Unpublished},
  howpublished = {Research paper},
  abstract = {The occurrence of uncorrected errors during PC operation are important because they affect the quality of user experience. Error types of interest include both corrected and uncorrected errors. Data from about 450,000 PCs worldwide, focusing on overclockable CPU, were acquired using Intel’s Data Collector and Analyzer (DCA) field data collector. We explored two topics: 1) For systems capable of overclocking, what is their dependence, in a four week monitoring period, of having one or more corrected, or various uncorrected, errors on a system’s maximum overclocking frequency, and total time overclocking; and 2) For both overclockable and non-overclockable systems, what is the probability of one or more uncorrected errors occurring on a system vs. the number of corrected errors it experienced in the time period. For 1), on five CPU we observe a strong relationship of all error types to both maximum overclocking frequency and total time overclocking. For 2), we found, during a given study time period, a PC is more likely to experience uncorrected errors as the number of corrected errors increases. That is, having more corrected errors is somewhat predictive of having one more uncorrected errors in a time period. We discuss plausible explanations of these results, and the implications for in-field product health management.}
}
@inproceedings{DinurReconstruction,
author = {Dinur, Irit and Nissim, Kobbi},
title = {Revealing information while preserving privacy},
year = {2003},
isbn = {1581136706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/773153.773173},
doi = {10.1145/773153.773173},
abstract = {We examine the tradeoff between privacy and usability of statistical databases. We model a statistical database by an n-bit string d1,..,dn, with a query being a subset q ⊆ [n] to be answered by Σiεq di. Our main result is a polynomial reconstruction algorithm of data from noisy (perturbed) subset sums. Applying this reconstruction algorithm to statistical databases we show that in order to achieve privacy one has to add perturbation of magnitude (Ω√n). That is, smaller perturbation always results in a strong violation of privacy. We show that this result is tight by exemplifying access algorithms for statistical databases that preserve privacy while adding perturbation of magnitude \~{O}(√n).For time-T bounded adversaries we demonstrate a privacypreserving access algorithm whose perturbation magnitude is ≈ √T.},
booktitle = {Proceedings of the Twenty-Second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
pages = {202–210},
numpages = {9},
keywords = {data reconstruction, integrity and security, subset-sums with noise},
location = {San Diego, California},
series = {PODS '03}
}

@article{DworkRoth,
url = {http://dx.doi.org/10.1561/0400000042},
year = {2014},
volume = {9},
journal = {Foundations and Trends® in Theoretical Computer Science},
title = {The Algorithmic Foundations of Differential Privacy},
doi = {10.1561/0400000042},
issn = {1551-305X},
number = {3–4},
pages = {211-407},
author = {Cynthia Dwork and Aaron Roth}
}

@unpublished{lassocarbon,
  author    = {Cheon, Seung Hyun},
  title     = {Power Consumption Patterns in Intel’s Telemetry Data: China Burns 2x Energy that of the US},
  note      = {2023},
  year      = {Unpublished},
  howpublished = {Research paper},
  abstract = {This paper examines the analysis of package power consumption using Intel’s telemetry data. It challenges the prevailingbelief that hardware choice is the primary determinant of a device’s power consumption and instead emphasizes the significantrole of user behavior. The paper includes two sections: Exploratory Data Analysis (EDA) and a linear model for powerconsumption. The EDA section provides valuable insights from Intel’s telemetry data, comparing power consumption acrosscountries, with a specific focus on power consumption patterns in the US and China. Our simple linear model affirms thosepatterns and highlight the possible importance of user behavior and its influence on power consumption. Ultimately, thepaper underscores the need to understand power consumption patterns and identifies areas where stakeholders like Intel canmake improvements to reduce environmental impact effectively and efficiently.}
}

@unpublished{kmeans,
  author    = {Ryan, Jacob M. and Feng, Shuangquan and McCusker, Marie and Smarr, Benjamin L and Saab, Rayan and de Sa, Virginia},
  title     = {PC Health Impact White Paper},
  note      = {Unpublished},
  year      = {Unpublished},
  howpublished = {Research paper},
  abstract = {Clustering different observations with multi-modal data across time is a complex task. Specifically,
when it comes to the data at hand, we are interested in a number of questions. How can we determine
if device behavior is changing? Are there different types of change present in the data? If so, can
the types of change be grouped? What differentiates one group from another? In this white paper,
we introduce tools that enables an investigator to detect changes in device usage, the direction of
that change, and the types of applications different groups of devices are using.}
}

@ARTICLE{prodhealLR,
  author={Su, Fei and Kwasnick, Robert and Holm, John and Penner, William and Gartler, Hermann and Boelter, Josh and Zhou, Yufei and Arbab, Bijan and Rothberg, Michael},
  journal={IEEE Design & Test}, 
  title={Product Health Insights Using Telemetry}, 
  year={2024},
  volume={41},
  number={4},
  pages={56-64},
  keywords={Telemetry;Computer bugs;Software;Monitoring;Measurement uncertainty;Codes;Temperature measurement;Telemetry;Product Health Monitoring and Management;PC errors;Logistic Regression},
  doi={10.1109/MDAT.2023.3317337}}

@article{FLandPrivacy,
author = {Bonawitz, Kallista and Kairouz, Peter and Mcmahan, Brendan and Ramage, Daniel},
title = {Federated learning and privacy},
year = {2022},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {65},
number = {4},
issn = {0001-0782},
url = {https://doi.org/10.1145/3500240},
doi = {10.1145/3500240},
abstract = {Building privacy-preserving systems for machine learning and data science on decentralized data.},
journal = {Commun. ACM},
month = mar,
pages = {90–97},
numpages = {8}
}

@article{DP-fyML,
   title={How to DP-fy ML: A Practical Guide to Machine Learning with Differential Privacy},
   volume={77},
   ISSN={1076-9757},
   url={http://dx.doi.org/10.1613/jair.1.14649},
   DOI={10.1613/jair.1.14649},
   journal={Journal of Artificial Intelligence Research},
   publisher={AI Access Foundation},
   author={Ponomareva, Natalia and Hazimeh, Hussein and Kurakin, Alex and Xu, Zheng and Denison, Carson and McMahan, H. Brendan and Vassilvitskii, Sergei and Chien, Steve and Thakurta, Abhradeep Guha},
   year={2023},
   month=jul, pages={1113–1201} }

@article{
DP-def,
author = {Andrea Gadotti  and Luc Rocher  and Florimond Houssiau  and Ana-Maria Creţu  and Yves-Alexandre de Montjoye },
title = {Anonymization: The imperfect science of using data while preserving privacy},
journal = {Science Advances},
volume = {10},
number = {29},
pages = {eadn7053},
year = {2024},
doi = {10.1126/sciadv.adn7053},
URL = {https://www.science.org/doi/abs/10.1126/sciadv.adn7053},
eprint = {https://www.science.org/doi/pdf/10.1126/sciadv.adn7053},
abstract = {Information about us, our actions, and our preferences is created at scale through surveys or scientific studies or as a result of our interaction with digital devices such as smartphones and fitness trackers. The ability to safely share and analyze such data is key for scientific and societal progress. Anonymization is considered by scientists and policy-makers as one of the main ways to share data while minimizing privacy risks. In this review, we offer a pragmatic perspective on the modern literature on privacy attacks and anonymization techniques. We discuss traditional de-identification techniques and their strong limitations in the age of big data. We then turn our attention to modern approaches to share anonymous aggregate data, such as data query systems, synthetic data, and differential privacy. We find that, although no perfect solution exists, applying modern techniques while auditing their guarantees against attacks is the best approach to safely use and share data today. Safe anonymization and sharing of personal data will be achieved by combining formal privacy methods with red-teaming.}}

@techreport{PewPrivacy2019,
  title = {Americans and Privacy: Concerned, Confused and Feeling Lack of Control Over Their Personal Information},
  author = {{Pew Research Center}},
  institution = {Pew Research Center},
  year = {2019},
  month = {November},
  type = {Report},
  url = {https://www.pewresearch.org/internet/2019/11/15/americans-and-privacy-concerned-confused-and-feeling-lack-of-control-over-their-personal-information/},
  note = {},
  keywords = {privacy, personal information, data control, public opinion}
}
@misc{su2015differentiallyprivatekmeansclustering,
      title={Differentially Private $k$-Means Clustering}, 
      author={Dong Su and Jianneng Cao and Ninghui Li and Elisa Bertino and Hongxia Jin},
      year={2015},
      eprint={1504.05998},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/1504.05998}, 
}
@unpublished{qtr1proj,
  author    = {Scheid, Trey and Kurpanek, Tyler and Lum, Christopher and Nathanson, Bradley and Wang, Yu-Xiang},
  title     = {Exploring Tradeoffs in Differential Privacy: An Empirical Study of Logistic Regression on Telemetry Data},
  url       = {https://github.com/Brqdley/DSC180AProject/blob/main/report.pdf%7D,
  note      = {Unpublished},
  year      = {2024},
  howpublished = {Research paper},
  abstract = {Across many domains, telemetry data encodes personally identifiable information that could be used to discover sensitive information. In order to balance the tradeoff between the accuracy and privacy of models and queries, many DP algorithms exist. However, few studies help individuals decide which approach to take. We analyze 4 different DP methods for privatizing logistic regression, and their performance tradeoffs in practice on telemetry data. We found gradient descent to best minimize error for a set privacy budget, which achieved the lowest error of .120 for an epsilon of 2 across all DP methods.}
}