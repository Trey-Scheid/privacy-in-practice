{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from autodp.autodp_core import Mechanism\n",
    "from autodp.mechanism_zoo import GaussianMechanism\n",
    "from autodp.transformer_zoo import ComposeGaussian\n",
    "from autodp.calibrator_zoo import eps_delta_calibrator\n",
    "from scipy.stats import logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From utils.py\n",
    "\n",
    "def get_data_fps(data_dir: str) -> list[str]:\n",
    "    data_fps = glob.glob(os.path.join(data_dir, \"*.csv\"))\n",
    "    data_fps = [data_fp for data_fp in data_fps if \"bugcheck\" in data_fp]\n",
    "    return data_fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../private_data/\"\n",
    "data_dir = os.path.abspath(data_dir)\n",
    "data_fps = get_data_fps(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_private_lr_results(data_fp):\n",
    "    df = pd.read_csv(data_fp)\n",
    "    \n",
    "    if df.groupby([\"has_corrected_error\", \"has_bugcheck\"]).size().shape[0] != 4:\n",
    "        df = pd.concat(\n",
    "            [df, pd.DataFrame({\"has_corrected_error\": [1], \"has_bugcheck\": [0]})],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        df = pd.concat(\n",
    "            [df, pd.DataFrame({\"has_corrected_error\": [1], \"has_bugcheck\": [1]})],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        \n",
    "    X = df[[\"has_corrected_error\"]]\n",
    "    X = 1*preprocessing.normalize(X, norm='l2')\n",
    "    \n",
    "    y = df[\"has_bugcheck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyGD_mech(Mechanism):\n",
    "    def __init__(self,sigma,coeff,name='NoisyGD'):\n",
    "        Mechanism.__init__(self)\n",
    "        self.name = name\n",
    "        self.params={'sigma':sigma,'coeff':coeff}\n",
    "        gm = GaussianMechanism(sigma,name='Release_gradient')\n",
    "        compose = ComposeGaussian() \n",
    "        mech = compose([gm], [coeff])\n",
    "        \n",
    "        \n",
    "        self.set_all_representation(mech)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class private_analysis:\n",
    "    def __init__(self, data_fp, epsilon, delta):\n",
    "        self.global_sensitivity = 1\n",
    "        self.df = pd.read_csv(data_fp)\n",
    "        self.epsilon = epsilon\n",
    "        proportion_fitting = 0.75\n",
    "        self.ep_fitting = self.epsilon * proportion_fitting\n",
    "        self.ep_pval = self.epsilon * (1 - proportion_fitting)\n",
    "        self.delta = delta\n",
    "        self.process_data()\n",
    "    \n",
    "    def process_data(self):\n",
    "        if self.df.groupby([\"has_corrected_error\", \"has_bugcheck\"]).size().shape[0] != 4:\n",
    "            self.df = pd.concat(\n",
    "                [self.df, pd.DataFrame({\"has_corrected_error\": [1], \"has_bugcheck\": [0]})],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "            self.df = pd.concat(\n",
    "                [self.df, pd.DataFrame({\"has_corrected_error\": [1], \"has_bugcheck\": [1]})],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "            \n",
    "        self.X = self.df[[\"has_corrected_error\"]]\n",
    "        self.X = np.hstack([np.ones((self.X.shape[0], 1)), self.X])\n",
    "        self.X = self.global_sensitivity*preprocessing.normalize(self.X, norm='l2')\n",
    "        \n",
    "        self.y = self.df[\"has_bugcheck\"]\n",
    "        \n",
    "        self.n = self.X.shape[0]\n",
    "        \n",
    "    def cross_entropy_loss(self, score, y):\n",
    "        log_phat = np.zeros_like(score)\n",
    "        log_one_minus_phat = np.zeros_like(score)\n",
    "        mask = score > 0\n",
    "        log_phat[mask] = -np.log(1 + np.exp(-score[mask]))\n",
    "        log_phat[~mask] = score[~mask] - np.log(1 + np.exp(score[~mask]))\n",
    "        log_one_minus_phat[~mask] = -np.log(1 + np.exp(score[~mask]))\n",
    "\n",
    "        return -y * log_phat - (1 - y) * log_one_minus_phat\n",
    "    \n",
    "    def loss(self, theta):\n",
    "        return np.sum(self.cross_entropy_loss(self.X@theta, self.y)) / self.n\n",
    "    \n",
    "    def err(self, theta):\n",
    "        return np.sum((self.X@theta > 0) != self.y) / self.n\n",
    "    \n",
    "    def gradient(self, theta):\n",
    "        grad = np.zeros(shape=(self.X.shape[1],))\n",
    "        \n",
    "        phat = np.exp(self.X@theta)/(1+np.exp(self.X@theta))\n",
    "        grad = self.X[self.y==0,:].T@(phat[self.y==0]) -self.X[self.y==1,:].T@(1-phat[self.y==1].T)\n",
    "        return grad\n",
    "\n",
    "    def GS_bound(self, theta):\n",
    "        \"\"\"\n",
    "        Calculate global sensitivity for a mini-batch.\n",
    "        \"\"\"\n",
    "        bound = np.linalg.norm(theta)\n",
    "        global_sensitivity = self.global_sensitivity / (1 + np.exp(-bound))\n",
    "        return global_sensitivity\n",
    "    \n",
    "    def find_appropriate_niter(self, sigma):\n",
    "        NoisyGD_fix_sigma = lambda x: NoisyGD_mech(sigma, x)\n",
    "        calibrate = eps_delta_calibrator()\n",
    "        mech = calibrate(NoisyGD_fix_sigma, self.ep_fitting, self.delta, [0, 500000])\n",
    "        niter = int(np.floor(mech.params[\"coeff\"]))\n",
    "        return niter\n",
    "    \n",
    "    def theoretical_lr_choice(self, beta_L, f0_minus_fniter_bound, dim, sigma, niter):\n",
    "        return np.minimum(\n",
    "            1 / beta_L,\n",
    "            np.sqrt(2 * f0_minus_fniter_bound / (dim * sigma**2 * beta_L * niter)),\n",
    "        )\n",
    "    \n",
    "    def run_NoisyGD_step(self, theta, sigma, lr):\n",
    "        global_sensitivity = self.GS_bound(theta)\n",
    "        return theta - lr * (self.gradient(theta) + global_sensitivity * sigma * np.random.normal(size=theta.shape))\n",
    "    \n",
    "    def run_NoisyGD(self, sigma, lr, niter, log_gap = 10, verbose=False):\n",
    "        theta_GD = np.zeros(shape=(self.X.shape[1],))\n",
    "        prev=theta_GD.copy()\n",
    "        \n",
    "        log_counter = 1\n",
    "        for i in range(niter):\n",
    "            theta_GD = self.run_NoisyGD_step(theta_GD, sigma, lr)\n",
    "            prev = ((prev * i) / (i + 1)) + (theta_GD / (i + 1))\n",
    "            if i == 0:\n",
    "                continue\n",
    "            if verbose and (not i % log_counter or i == niter - 1):\n",
    "                mech = NoisyGD_mech(sigma, i + 1)\n",
    "                print(\"iteration\", i, \"epsilon\", mech.approxDP(self.delta), \"loss\", self.loss(theta_GD), \"params\", theta_GD)\n",
    "                log_counter *= log_gap\n",
    "        \n",
    "        self.theta = theta_GD\n",
    "        return theta_GD[1], self.loss(theta_GD)\n",
    "    \n",
    "    # def permutation_test(self, n_permutations=1000, alpha=0.05):\n",
    "    #     if self.theta is None:\n",
    "    #         raise ValueError(\"theta must be computed before permutation test\")\n",
    "        \n",
    "    #     def compute_test_statistic(X: np.ndarray, y: np.ndarray, theta: np.ndarray) -> float:\n",
    "    #         logits = X @ theta\n",
    "    #         probs = logistic.cdf(logits)\n",
    "    #         ll = np.sum(y * np.log(probs + 1e-10) + (1 - y) * np.log(1 - probs + 1e-10))\n",
    "            \n",
    "    #         return -2 * ll\n",
    "    \n",
    "    #     observed_stat = compute_test_statistic(self.X, self.y, self.theta)\n",
    "        \n",
    "    #     sensitivity = np.sqrt(2 * np.log(1.25/self.delta)) / self.ep_pval\n",
    "        \n",
    "    #     null_distribution = []\n",
    "    #     for _ in range(n_permutations):\n",
    "    #         y_perm = np.random.permutation(self.y)\n",
    "    #         dp_noise = np.random.normal(0, sensitivity)\n",
    "    #         perm_stat = compute_test_statistic(self.X, y_perm, self.theta) + dp_noise\n",
    "    #         null_distribution.append(perm_stat)\n",
    "        \n",
    "    #     null_distribution = np.array(null_distribution)\n",
    "    #     p_value = np.mean(null_distribution >= observed_stat)\n",
    "        \n",
    "    #     return p_value\n",
    "    \n",
    "    # TODO: some sort of p-value calculation\n",
    "    \n",
    "    def fit(self, sigma=300.0, log_gap=10, verbose=False):\n",
    "        beta = 1 / 4 * self.n\n",
    "        \n",
    "        f0_minus_fniter_bound = self.n * (-np.log(0.5))\n",
    "        \n",
    "        niter = self.find_appropriate_niter(sigma)\n",
    "        lr = self.theoretical_lr_choice(beta, f0_minus_fniter_bound, self.X.shape[1], sigma, niter)\n",
    "        if verbose:\n",
    "            print(\"niter\", niter, \"lr\", lr)\n",
    "        param, loss = self.run_NoisyGD(sigma, lr, niter, log_gap, verbose)\n",
    "        \n",
    "        return param, loss\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = private_analysis(data_fps[0], 2, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first.fit(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fps[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffpriv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
